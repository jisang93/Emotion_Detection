{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599474662739",
   "display_name": "Python 3.8.5 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **데이터 전처리**\n",
    "**이미지 불러오기 및 라벨링 순서**\n",
    "\n",
    "1. 데이터셋 폴더 생성\n",
    "2. 아래 이름의 일곱 가지의 폴더 생성 및 데이터 분류\n",
    "\n",
    "    anger, digust, fear, happy, neutral, sadness, surprise\n",
    "    \n",
    "    (분노, 혐오, 공포, 행복, 기본, 슬픔, 놀람)\n",
    "\n",
    "3. 각 폴더 안의 데이터 파일 불러오기\n",
    "4. Face Detection 모델을 사용해 얼굴 이미지만 추리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 이미지 파일 디렉토리 연결\n",
    "modeling_images = 'C:/Users/jisan/workspace/표정 감정 분석/Emotion_Detection/Data_Crawling/Data_Set'\n",
    "\n",
    "# 이미지 파일, 이모션 라벨 리스트\n",
    "image_list = []\n",
    "emotion_label = []\n",
    "\n",
    "# 이미지와 라벨 리스트에 담기\n",
    "for i in os.listdir(modeling_images):\n",
    "    for j in os.listdir('C:/Users/jisan/workspace/표정 감정 분석/Emotion_Detection/Data_Crawling/Data_Set'+i+'/'):\n",
    "        if 'png' or 'tiff' or 'jpg' in j:\n",
    "            image_list.append(modeling_images + i + '/' + j)\n",
    "            emotion_label.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_list), len(emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imread를 이용해 불러온 이미지 확인\n",
    "img = cv2.imread(image_list[0])\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(img[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Face Detection을 이용해 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Face Detection을 이용해 얼굴 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성\n",
    "img_result = []\n",
    "face_result = []\n",
    "emotion_result = []\n",
    "\n",
    "# 얼굴 디렉터 모듈 초기화\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# object 디텍션 모듈 초기화\n",
    "objs = dlib.full_object_detections()\n",
    "# 얼굴 특징점 모듈 초기화\n",
    "predictor = dlib.shape_predictor('C:/Users/jisan/workspace/표정 감정 분석/Emotion_Detection/Data_Preprocessing/models/shape_predictor_5_face_landmarks.dat')\n",
    "\n",
    "# align_faces 함수 정의\n",
    "def align_faces(img):\n",
    "    dets = detector(img, 1)\n",
    "    objs = dlib.full_object_detections()\n",
    "    for detection in dets:\n",
    "        s = predictor(img, detection)\n",
    "        objs.append(s)\n",
    "    faces = dlib.get_face_chips(img, objs, size=256, padding=0.35)\n",
    "    return faces\n",
    "\n",
    "# 이미지 저장\n",
    "for i, img in enumerate(image_list):\n",
    "    # img를 image 형태로 변경\n",
    "    img = cv2.imread(img)\n",
    "    # 얼굴 인식\n",
    "    try:\n",
    "        faces = align_faces(img)[0]\n",
    "        # 얼굴이 인식된 원본 사진 저장\n",
    "        img_result.append(img)\n",
    "        # 얼굴이 인식된 감정 라벨 저장\n",
    "        emotion_result.append(emotion_label[i])\n",
    "        # 얼굴이 인식된 얼굴 사진 저장\n",
    "        face_result.append(faces)\n",
    "    except RuntimeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 리스트별 길이 확인\n",
    "len(img_result), len(emotion_result), len(face_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face_result 결과 확인\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,5))\n",
    "axes[0].imshow(img_result[0], 3)\n",
    "axes[1].imshow(face_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Pickle 형태 데이터 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 세이브\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open(\"data.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(img_result, fw)\n",
    "with gzip.open(\"label.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(emotion_result, fw)\n",
    "with gzip.open(\"face.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(face_result, fw)"
   ]
  }
 ]
}